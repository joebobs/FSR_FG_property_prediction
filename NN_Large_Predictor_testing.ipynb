{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Joe\\Acads\\Sem8\\DDP\\Code files\\FSR\n"
     ]
    }
   ],
   "source": [
    "%cd D:\\Joe\\Acads\\Sem8\\DDP\\Code files\\FSR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn \n",
    "from nn_config import NN_config\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "\n",
    "class NN_Large_Predictor(nn.Sequential):\n",
    "\n",
    "\tdef make_encoder(self, enc_dims, dec_dims):\n",
    "\t\tnum_enc = len(enc_dims)\n",
    "\t\tnum_dec = len(dec_dims)\n",
    "\t\tencoder = []\n",
    "\t\tdecoder = []\n",
    "\t\tfor i in range(num_enc-1):\n",
    "\t\t\tif i != 0:\n",
    "\t\t\t\tencoder += [nn.ReLU(True), nn.Linear(enc_dims[i], enc_dims[i+1])]\n",
    "\t\t\telse:\n",
    "\t\t\t\tencoder.append(nn.Linear(enc_dims[i], enc_dims[i+1]))\n",
    "\t\tfor i in range(num_dec-1):\n",
    "\t\t\tif i != 0:\n",
    "\t\t\t\tdecoder += [nn.ReLU(True), nn.Linear(dec_dims[i], dec_dims[i+1])] \n",
    "\t\t\telse:\n",
    "\t\t\t\tdecoder.append(nn.Linear(dec_dims[i], dec_dims[i+1]))\n",
    "\t\treturn torch.nn.Sequential(*(encoder)), torch.nn.Sequential(*(decoder))\n",
    "\n",
    "\tdef __init__(self, **config):\n",
    "\t\tsuper(NN_Large_Predictor, self).__init__()\n",
    "\t\tself.input_dim = config['input_dim']\n",
    "\t\tself.encode_fc1_dim = config['encode_fc1_dim']\n",
    "\t\tself.encode_fc2_dim = config['encode_fc2_dim']\n",
    "\t\tself.decode_fc1_dim = config['decode_fc1_dim']\n",
    "\t\tself.decode_fc2_dim = config['decode_fc2_dim']\n",
    "\t\tself.cat_flag = False\n",
    "\t\tself.num_flag = False\n",
    "\n",
    "\t\t#self.ffn_input = config['features_size'] + config['encode_fc2_dim']\n",
    "\t\tself.ffn_input = config['encode_fc2_dim']\n",
    "\n",
    "\t\tif config['cat_features_size']>0:\n",
    "\t\t\tself.cat_flag = True\n",
    "\t\t\tself.cat_input_dim = config['cat_features_size']\n",
    "\t\t\tself.cat_encode_fc1_dim = config['cat_encode_fc1_dim']\n",
    "\t\t\tself.cat_encode_fc2_dim = config['cat_encode_fc2_dim']\n",
    "\t\t\tself.cat_decode_fc1_dim = config['cat_decode_fc1_dim']\n",
    "\t\t\tself.cat_decode_fc2_dim = config['cat_decode_fc2_dim']\n",
    "\t\t\tcat_enc_dims = [self.cat_input_dim, self.cat_encode_fc1_dim, self.cat_encode_fc2_dim]\n",
    "\t\t\tcat_dec_dims = [self.cat_encode_fc2_dim, self.cat_decode_fc1_dim, self.cat_decode_fc2_dim]\n",
    "\t\t\tself.cat_encoder, self.cat_decoder = self.make_encoder(cat_enc_dims, cat_dec_dims)\n",
    "\n",
    "\t\t\tself.ffn_input += cat_enc_dims[-1]\n",
    "\n",
    "\t\tif config['num_features_size']>0 and config['extra_features'] == True:\n",
    "\t\t\tself.num_flag = True\n",
    "\t\t\tself.num_input_dim = config['num_features_size']\n",
    "\t\t\tself.num_encode_fc1_dim = config['num_encode_fc1_dim']\n",
    "\t\t\tself.num_encode_fc2_dim = config['num_encode_fc2_dim']\n",
    "\t\t\tself.num_decode_fc1_dim = config['num_decode_fc1_dim']\n",
    "\t\t\tself.num_decode_fc2_dim = config['num_decode_fc2_dim']\n",
    "\t\t\tnum_enc_dims = [self.num_input_dim, self.num_encode_fc1_dim, self.num_encode_fc2_dim]\n",
    "\t\t\tnum_dec_dims = [self.num_encode_fc2_dim, self.num_decode_fc1_dim, self.num_decode_fc2_dim]\n",
    "\t\t\tself.num_encoder, self.num_decoder = self.make_encoder(num_enc_dims, num_dec_dims)\n",
    "\n",
    "\t\t\tself.ffn_input += num_enc_dims[-1]\n",
    "\n",
    "\t\tself.predict_dim = config['predict_dim']\n",
    "\t\tself.predict_out_dim = config['predict_out_dim']\n",
    "\t\t\n",
    "\t\tself.dropout_ratio = config['dropout']\n",
    "\t\tself.ffn_num_layers = config['ffn_num_layers']\n",
    "\t\tprint(\"input dim:\", self.input_dim, \"encode dim:\", self.encode_fc1_dim)\n",
    "\n",
    "\t\tenc_dims = [self.input_dim, self.encode_fc1_dim, self.encode_fc2_dim]\n",
    "\t\tdec_dims = [self.encode_fc2_dim, self.decode_fc1_dim, self.decode_fc2_dim]\n",
    "\t\tself.encoder, self.decoder = self.make_encoder(enc_dims, dec_dims)\n",
    "\n",
    "\t\t'''if self.feature_input_dim:\n",
    "\t\t\tself.features_ffn = nn.Sequential(\n",
    "\t\t\t\tnn.Linear(self.feature_input_dim, self.feature_fc1_dim),\n",
    "\t\t\t\tnn.Sigmoid()\n",
    "\t\t\t)'''\n",
    "\n",
    "\t\tself.create_predictor()\n",
    "\n",
    "\tdef create_predictor(self):\n",
    "\t\t\n",
    "\t\tdropout = nn.Dropout(self.dropout_ratio)\n",
    "\t\tactivation = nn.ReLU()\n",
    "\n",
    "\t\tif self.ffn_num_layers == 1:\n",
    "\t\t\tpredictor = [\n",
    "                dropout,\n",
    "                nn.Linear(self.ffn_input, self.predict_out_dim)\n",
    "            ]\n",
    "\t\telse:\n",
    "\t\t\tpredictor = [\n",
    "                dropout,\n",
    "                nn.Linear(self.ffn_input, self.predict_dim)\n",
    "            ]\n",
    "\t\t\tpredictor.extend([\n",
    "                activation,\n",
    "                dropout,\n",
    "                nn.Linear(self.predict_dim, self.predict_dim//2),\n",
    "            ])\n",
    "\t\t\tfor _ in range(self.ffn_num_layers - 3):\n",
    "\t\t\t\tpredictor.extend([\n",
    "                    activation,\n",
    "                    dropout,\n",
    "                    nn.Linear(self.predict_dim//2, self.predict_dim//2),\n",
    "                ])\n",
    "\t\t\tpredictor.extend([\n",
    "                activation,\n",
    "                dropout,\n",
    "                nn.Linear(self.predict_dim//2, self.predict_out_dim),\n",
    "            ])\n",
    "\n",
    "\t\t# Create predictor model\n",
    "\t\tself.predictor = nn.Sequential(*predictor)\n",
    "\n",
    "\tdef forward(self, v_D, cat_features = None, num_features=None):\n",
    "\t\t'''\n",
    "\t\t:param v_D: batch_size x eta, multi-hot vector\n",
    "\t\t:return: recon, score, code\n",
    "\t\t'''\n",
    "\t\tZ_D = self.encoder(v_D.to(device))\n",
    "\t\t# # decode\n",
    "\t\tv_D_hat = self.decoder(Z_D)\n",
    "\t\trecon  = torch.sigmoid(v_D_hat)\n",
    "\n",
    "\t\tcat_recon = None\n",
    "\t\tnum_recon = None\n",
    "\t\t#if features_batch is not None:\n",
    "\t\tif self.cat_flag:\n",
    "\t\t\tprint('Hello1')\n",
    "\t\t\tassert cat_features != None \n",
    "\t\t\t#Z_D_extended = torch.cat([Z_D, features_batch], dim=1)\n",
    "\t\t\tcat_e = self.cat_encoder(cat_features.to(device))\n",
    "\t\t\tcat_hat = self.cat_decoder(cat_e)\n",
    "\t\t\tcat_recon = torch.sigmoid(cat_hat)\n",
    "\t\t\tZ_D = torch.cat([Z_D, cat_e], dim=1)  \n",
    "\t\tself.num_flag = False ##### REMOVE THIS\n",
    "\t\tZ_D = torch.cat([Z_D, num_features.to(device)], dim=1) ###### REMOVE THIS\n",
    "\t\tif self.num_flag:\n",
    "\t\t\tprint('Hello2')\n",
    "\t\t\tassert num_features != None\n",
    "\t\t\tnum_e = self.num_encoder(num_features.to(device))\n",
    "\t\t\tnum_hat = self.num_decoder(num_e)\n",
    "\t\t\tnum_recon = torch.sigmoid(num_hat)\n",
    "\t\t\tZ_D = torch.cat([Z_D, num_e], dim=1) \n",
    "\n",
    "\t\tscore = self.predictor(Z_D)\n",
    "\t\treturn  recon, cat_recon, num_recon, score, Z_D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = NN_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "from chemprop.features import load_features\n",
    "import pickle\n",
    "\n",
    "main_dir = '.\\\\'\n",
    "if 'main_dir' in config.keys():\n",
    "    main_dir = config['main_dir']\n",
    "data_dir = os.path.join(main_dir, 'Data')\n",
    "data_path =  os.path.join(data_dir, config['file_name'])\n",
    "\n",
    "if config['extra_features']:\n",
    "    features_data = []\n",
    "    features_path = os.path.join(data_dir, config['features_filename'])\n",
    "    features_data.append(load_features(features_path))\n",
    "    features_data = np.concatenate(features_data, axis=1)\n",
    "    features_data[:,32] = np.log(features_data[:,32]+1) ##### Done because of the huge range of the feature\n",
    "    if not config['feature_categorical_columns'] == None:\n",
    "        categorical_idx = config['feature_categorical_columns']\n",
    "        numeric = features_data[:,[not (i in categorical_idx) for i in range(features_data.shape[1])]]\n",
    "        categorical = features_data[:,[(i in categorical_idx) for i in range(features_data.shape[1])]]\n",
    "        # TODO: save the OHE from a large corpus\n",
    "        #categorical = OneHotEncoder().fit_transform(categorical)\n",
    "        with open(r\"D:\\Joe\\Acads\\Sem8\\DDP\\Code files\\FSR\\Data\\features\\ohe_list\", \"rb\") as f:\n",
    "            ohe_list = pickle.load(f)\n",
    "        inp = categorical\n",
    "        cat_encoded = None\n",
    "        for idx in range(108):\n",
    "            temp = ohe_list[idx].transform(inp[:,idx].reshape(-1,1))\n",
    "            if not isinstance(cat_encoded, np.ndarray):\n",
    "                cat_encoded = temp\n",
    "            else:\n",
    "                cat_encoded = np.concatenate([cat_encoded, temp], axis = 1)\n",
    "        #features_data = np.concatenate([numeric, categorical.toarray()], axis = 1)\n",
    "        features_data = [cat_encoded, numeric]\n",
    "    __, config['cat_features_size'] = features_data[0].shape\n",
    "    config['cat_decode_fc2_dim'] = config['cat_features_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input dim: 2586 encode dim: 1000\n"
     ]
    }
   ],
   "source": [
    "model = NN_Large_Predictor(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  NN_Large_Predictor(\n",
      "  (cat_encoder): Sequential(\n",
      "    (0): Linear(in_features=2153, out_features=300, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Linear(in_features=300, out_features=20, bias=True)\n",
      "  )\n",
      "  (cat_decoder): Sequential(\n",
      "    (0): Linear(in_features=20, out_features=300, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Linear(in_features=300, out_features=2153, bias=True)\n",
      "  )\n",
      "  (num_encoder): Sequential(\n",
      "    (0): Linear(in_features=92, out_features=70, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Linear(in_features=70, out_features=30, bias=True)\n",
      "  )\n",
      "  (num_decoder): Sequential(\n",
      "    (0): Linear(in_features=30, out_features=70, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Linear(in_features=70, out_features=92, bias=True)\n",
      "  )\n",
      "  (encoder): Sequential(\n",
      "    (0): Linear(in_features=2586, out_features=1000, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Linear(in_features=1000, out_features=200, bias=True)\n",
      "  )\n",
      "  (decoder): Sequential(\n",
      "    (0): Linear(in_features=200, out_features=1000, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Linear(in_features=1000, out_features=2586, bias=True)\n",
      "  )\n",
      "  (predictor): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Linear(in_features=250, out_features=1500, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=1500, out_features=750, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Dropout(p=0.5, inplace=False)\n",
      "    (7): Linear(in_features=750, out_features=750, bias=True)\n",
      "    (8): ReLU()\n",
      "    (9): Dropout(p=0.5, inplace=False)\n",
      "    (10): Linear(in_features=750, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1 cat_encoder Sequential(\n",
      "  (0): Linear(in_features=2153, out_features=300, bias=True)\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): Linear(in_features=300, out_features=20, bias=True)\n",
      ")\n",
      "2 cat_encoder.0 Linear(in_features=2153, out_features=300, bias=True)\n",
      "3 cat_encoder.1 ReLU(inplace=True)\n",
      "4 cat_encoder.2 Linear(in_features=300, out_features=20, bias=True)\n",
      "5 cat_decoder Sequential(\n",
      "  (0): Linear(in_features=20, out_features=300, bias=True)\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): Linear(in_features=300, out_features=2153, bias=True)\n",
      ")\n",
      "6 cat_decoder.0 Linear(in_features=20, out_features=300, bias=True)\n",
      "7 cat_decoder.1 ReLU(inplace=True)\n",
      "8 cat_decoder.2 Linear(in_features=300, out_features=2153, bias=True)\n",
      "9 num_encoder Sequential(\n",
      "  (0): Linear(in_features=92, out_features=70, bias=True)\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): Linear(in_features=70, out_features=30, bias=True)\n",
      ")\n",
      "10 num_encoder.0 Linear(in_features=92, out_features=70, bias=True)\n",
      "11 num_encoder.1 ReLU(inplace=True)\n",
      "12 num_encoder.2 Linear(in_features=70, out_features=30, bias=True)\n",
      "13 num_decoder Sequential(\n",
      "  (0): Linear(in_features=30, out_features=70, bias=True)\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): Linear(in_features=70, out_features=92, bias=True)\n",
      ")\n",
      "14 num_decoder.0 Linear(in_features=30, out_features=70, bias=True)\n",
      "15 num_decoder.1 ReLU(inplace=True)\n",
      "16 num_decoder.2 Linear(in_features=70, out_features=92, bias=True)\n",
      "17 encoder Sequential(\n",
      "  (0): Linear(in_features=2586, out_features=1000, bias=True)\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): Linear(in_features=1000, out_features=200, bias=True)\n",
      ")\n",
      "18 encoder.0 Linear(in_features=2586, out_features=1000, bias=True)\n",
      "19 encoder.1 ReLU(inplace=True)\n",
      "20 encoder.2 Linear(in_features=1000, out_features=200, bias=True)\n",
      "21 decoder Sequential(\n",
      "  (0): Linear(in_features=200, out_features=1000, bias=True)\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): Linear(in_features=1000, out_features=2586, bias=True)\n",
      ")\n",
      "22 decoder.0 Linear(in_features=200, out_features=1000, bias=True)\n",
      "23 decoder.1 ReLU(inplace=True)\n",
      "24 decoder.2 Linear(in_features=1000, out_features=2586, bias=True)\n",
      "25 predictor Sequential(\n",
      "  (0): Dropout(p=0.5, inplace=False)\n",
      "  (1): Linear(in_features=250, out_features=1500, bias=True)\n",
      "  (2): ReLU()\n",
      "  (3): Dropout(p=0.5, inplace=False)\n",
      "  (4): Linear(in_features=1500, out_features=750, bias=True)\n",
      "  (5): ReLU()\n",
      "  (6): Dropout(p=0.5, inplace=False)\n",
      "  (7): Linear(in_features=750, out_features=750, bias=True)\n",
      "  (8): ReLU()\n",
      "  (9): Dropout(p=0.5, inplace=False)\n",
      "  (10): Linear(in_features=750, out_features=1, bias=True)\n",
      ")\n",
      "26 predictor.0 Dropout(p=0.5, inplace=False)\n",
      "27 predictor.1 Linear(in_features=250, out_features=1500, bias=True)\n",
      "28 predictor.2 ReLU()\n",
      "29 predictor.4 Linear(in_features=1500, out_features=750, bias=True)\n",
      "30 predictor.7 Linear(in_features=750, out_features=750, bias=True)\n",
      "31 predictor.10 Linear(in_features=750, out_features=1, bias=True)\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "for name, item in model.named_modules():\n",
    "    print(idx, name, item)\n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
